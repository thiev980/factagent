---
title: FactAgent â€“ Faktencheck-Assistent
emoji: ğŸ”
colorFrom: blue
colorTo: purple
sdk: docker
app_port: 7860
pinned: false
license: mit
---

# ğŸ” FactAgent â€“ Interaktiver Faktencheck-Assistent

Ein AI-powered Faktencheck-Tool, das Behauptungen automatisch zerlegt, im Web recherchiert, Quellen bewertet und ein strukturiertes Verdikt liefert.

**[â–¶ Live Demo â†’](https://thiev980-factagent.hf.space)**

![Python](https://img.shields.io/badge/Python-3.11+-blue)
![Claude API](https://img.shields.io/badge/LLM-Claude%20API-orange)
![LangGraph](https://img.shields.io/badge/Orchestration-LangGraph-green)
![Chainlit](https://img.shields.io/badge/Frontend-Chainlit-purple)
![License](https://img.shields.io/badge/License-MIT-green)

---

<!-- Screenshots: ersetze die Platzhalter mit deinen eigenen Bildern -->
<p align="center">
  <img src="docs/screenshot-verdict.png" alt="FactAgent Verdict" width="700">
</p>
<p align="center"><em>FactAgent zerlegt Behauptungen, recherchiert Quellen und liefert ein strukturiertes Verdikt</em></p>

<p align="center">
  <img src="docs/screenshot-source-graph.png" alt="Source Graph" width="700">
</p>
<p align="center"><em>Interaktiver Source Graph: Welche Quellen stÃ¼tzen welche Teilaussagen?</em></p>

## Was macht FactAgent?

Du gibst eine Behauptung ein â€“ FactAgent Ã¼berprÃ¼ft sie:

```
Input:  "Die Schweiz hat die hÃ¶chste Einwanderungsrate in Europa."
Output: ğŸŸ¡ Teilweise wahr (78% Konfidenz)
        Die Schweiz hat eine der hÃ¶chsten Einwanderungsraten in Europa,
        liegt aber hinter Luxemburg und Malta...
```

## AI-Engineering-Patterns

Dieses Projekt demonstriert 8 AI-Engineering-Konzepte:

### 1. Agentic Workflow (ReAct Pattern)
Der Agent durchlÃ¤uft autonom 4 Schritte â€“ nicht ein einzelner API-Call, sondern eine orchestrierte Pipeline:

```
Claim Decomposer â†’ Evidence Retriever â†’ Source Evaluator â†’ Verdict Synthesizer
```

### 2. RAG (Retrieval Augmented Generation)
Das LLM recherchiert aktiv im Web, statt sich auf Trainingsdaten zu verlassen. Jede Aussage wird mit aktuellen, externen Quellen abgeglichen.

### 3. Structured Output
Jeder LLM-Call liefert validiertes JSON (via Pydantic Models) â€“ keine Freitext-Interpretation nÃ¶tig. Bei Parse-Fehlern greift ein automatischer Retry-Mechanismus mit JSON-Reparatur.

### 4. Prompt Engineering
Jeder Agent-Schritt hat einen spezialisierten Prompt mit Rollenanweisung, Beispielen und Constraints. Prompts sind dokumentiert und versioniert.

### 5. Streaming
Token-by-Token Streaming fÃ¼r Echtzeit-Feedback. Die Zusammenfassung wird live geschrieben, wÃ¤hrend der User zuschaut. Implementiert mit AsyncAnthropic und Chainlit Streaming.

### 6. Human-in-the-Loop
Nach der automatischen Bewertung kann der User jedes Teilurteil Ã¼berprÃ¼fen und korrigieren. Menschliche Korrekturen fliessen gewichtet in das Gesamtverdikt ein.

### 7. Historische Claims (Knowledge Base)
SQLite-Datenbank mit FTS5 Full-Text Search speichert alle Checks. Ã„hnliche frÃ¼here Behauptungen werden erkannt, um redundante API-Calls zu vermeiden.

### 8. Source Graph (Explainability)
Interaktive vis.js-Netzwerk-Visualisierung zeigt, welche Quellen welche Teilaussagen stÃ¼tzen. Farben kodieren Verdikt und GlaubwÃ¼rdigkeit.

### Evaluation
Ein Eval-Set mit 15 Behauptungen (bekannte Verdikts) ermÃ¶glicht systematisches Testen und Accuracy-Tracking.

## Architektur

```
User Input (Behauptung)
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Claim Decomposer   â”‚  LLM-Call: Zerlegt in Teilaussagen
â”‚  (Claude Sonnet)     â”‚  + generiert Suchanfragen
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Evidence Retriever  â”‚  Tavily API: Web Search + Extraktion
â”‚  (Tavily Search)     â”‚  Deduplizierung, Ranking
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Source Evaluator     â”‚  LLM-Call: Relevanz, GlaubwÃ¼rdigkeit,
â”‚  (Claude Sonnet)     â”‚  Verdikt pro Teilaussage
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ‘¤ Human Review     â”‚  User kann Verdikts korrigieren
â”‚  (optional)          â”‚  oder Kontext hinzufÃ¼gen
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Verdict Synthesizer â”‚  LLM-Call: Gesamtbewertung mit
â”‚  (Claude Sonnet)     â”‚  Zusammenfassung und Quellen
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â†’ ğŸ’¾ SQLite (Historische Claims)
         â”œâ”€â”€â†’ ğŸ•¸ï¸ Source Graph (vis.js HTML)
         â”‚
         â–¼
   Chat UI (Chainlit)
```

## Tech Stack

| Komponente | Technologie | Warum? |
|---|---|---|
| LLM | Claude API (Sonnet) | Starke Reasoning-FÃ¤higkeiten, gutes Preis-Leistungs-VerhÃ¤ltnis |
| Orchestrierung | LangGraph | State-Management, Routing, Error Handling |
| Web Search | Tavily API | Speziell fÃ¼r AI-Agents gebaut, hohe QualitÃ¤t |
| Structured Output | Pydantic v2 | Schema-Validierung, Typsicherheit |
| Frontend | Chainlit | Chat-UI mit Step-Visualisierung + Streaming |
| Datenbank | SQLite + FTS5 | Zero-Config, Full-Text Search eingebaut |
| Visualisierung | vis.js | Interaktive Netzwerk-Graphen |
| Deployment | HF Spaces (Docker) | Kostenlos, AI-Community |

## Lokale Installation

### Voraussetzungen
- Python 3.11+
- Anthropic API Key ([console.anthropic.com](https://console.anthropic.com/))
- Tavily API Key ([tavily.com](https://tavily.com/) â€“ kostenloser Tier)

### Installation

```bash
# Repository klonen
git clone https://github.com/DEIN-USERNAME/factagent.git
cd factagent

# Virtual Environment erstellen
python -m venv venv
source venv/bin/activate  # macOS/Linux

# Dependencies installieren
pip install -r requirements.txt

# API-Keys konfigurieren
cp .env.example .env
# â†’ .env editieren und Keys eintragen
```

### Starten

```bash
chainlit run app.py
# â†’ Ã–ffnet http://localhost:8000
```

### Chat-Befehle

| Befehl | Beschreibung |
|---|---|
| `/history` | Letzte 10 Faktenchecks anzeigen |
| `/stats` | Statistiken (Anzahl, Verdikts, etc.) |

### Evaluation ausfÃ¼hren

```bash
python -m eval.run_eval          # Alle 15 Test-Claims
python -m eval.run_eval --limit 5  # Nur die ersten 5
```

## Deployment (Hugging Face Spaces)

1. Space erstellen auf [huggingface.co/new-space](https://huggingface.co/new-space)
   - SDK: **Docker**
   - Visibility: Public oder Private
2. Secrets hinzufÃ¼gen (Settings â†’ Variables and Secrets):
   - `ANTHROPIC_API_KEY`
   - `TAVILY_API_KEY`
3. Code pushen:
   ```bash
   git remote add hf https://huggingface.co/spaces/DEIN-USERNAME/factagent
   git push hf main
   ```

Die App startet automatisch und ist unter `https://DEIN-USERNAME-factagent.hf.space` erreichbar.

## Projektstruktur

```
factagent/
â”œâ”€â”€ app.py                  # Chainlit Web App (Frontend + HITL)
â”œâ”€â”€ Dockerfile              # HF Spaces Deployment
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example            # API-Key Template
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ models.py           # Pydantic Models (Structured Output)
â”‚   â”œâ”€â”€ prompts.py          # Alle Prompts (Prompt Engineering)
â”‚   â”œâ”€â”€ tools.py            # Tavily Search (RAG)
â”‚   â”œâ”€â”€ nodes.py            # Agent-Schritte (Streaming + Retry)
â”‚   â”œâ”€â”€ graph.py            # LangGraph Workflow (Orchestrierung)
â”‚   â”œâ”€â”€ database.py         # SQLite + FTS5 (Historische Claims)
â”‚   â”œâ”€â”€ source_graph.py     # vis.js Netzwerk-Visualisierung
â”‚   â””â”€â”€ rate_limiter.py     # API-Schutz fÃ¼r Ã¶ffentliches Deployment
â”œâ”€â”€ eval/
â”‚   â”œâ”€â”€ eval_set.json       # 15 Test-Behauptungen
â”‚   â””â”€â”€ run_eval.py         # Evaluations-Script
â””â”€â”€ README.md
```

## Verdikt-Kategorien

| Verdikt | Emoji | Bedeutung |
|---|---|---|
| `true` | âœ… | Durch Evidenz bestÃ¤tigt |
| `false` | âŒ | Durch Evidenz widerlegt |
| `partially_true` | ğŸŸ¡ | Teilweise korrekt, mit EinschrÃ¤nkungen |
| `misleading` | âš ï¸ | Technisch korrekt, aber irrefÃ¼hrend |
| `unverifiable` | â“ | Nicht genÃ¼gend verlÃ¤ssliche Quellen |

## Kosten

Pro Faktencheck fallen ca. 3-5 Claude API Calls an (Sonnet):
- Claim Decomposition: ~500 Input + 500 Output Tokens
- Evidence Evaluation: ~2000 Input + 500 Output Tokens (pro Teilaussage)
- Verdict Synthesis: ~2000 Input + 500 Output Tokens
- Streaming Summary: ~1000 Input + 500 Output Tokens
- Tavily: 1000 kostenlose Suchen/Monat

**GeschÃ¤tzt: ~$0.01-0.03 pro Faktencheck** (mit Claude Sonnet)

## Ãœber mich

Data Analyst mit Hintergrund in Soziologie â€“ fokussiert auf die Schnittstelle von Gesellschaft, Medien und KI. Dieses Projekt entstand als Portfolio-Showcase fÃ¼r AI Engineering.

---

*Built with Claude API, LangGraph, Tavily, Chainlit, and vis.js*
